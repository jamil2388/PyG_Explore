{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d265f90c-a403-4721-b48c-a942b1c882fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30585771-a71a-41b0-a1ea-c6bff018b06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 4, 2, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.randint(0, 5, (3,)), torch.tensor((2, 2)), torch.randint(0, 5, (3,))], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942a8b9a-1317-40ff-bcca-97b35564bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MetaPath2Vec\n",
    "from gnn import Gnn\n",
    "from tqdm import tqdm\n",
    "from src.mdl.team2vec.params import settings\n",
    "import os\n",
    "\n",
    "class M2V(Gnn):\n",
    "    def __init__(self, teamsvecs, indexes, settings, output, emb_output): # must provide emb_output for gnn methods\n",
    "        super().__init__(teamsvecs, indexes, settings, output)\n",
    "\n",
    "        self.settings = {\n",
    "            'e': 5,\n",
    "            'd': 10,\n",
    "            'b': 10,\n",
    "            'ns': 5,\n",
    "            'metapath': [],\n",
    "            'walk_length': settings['model']['gnn.m2v']['walk_length'],\n",
    "            'context_size': settings['model']['gnn.m2v']['context_size'],\n",
    "            'walks_per_node': settings['model']['gnn.m2v']['walks_per_node'],\n",
    "        }\n",
    "        self.model_name = 'm2v'\n",
    "        self.emb_output = emb_output + f'{self.model_name}.stm.undir.mean.e{self.settings[\"e\"]}.ns{self.settings[\"ns\"]}.b{self.settings[\"b\"]}.d{self.settings[\"d\"]}'  # output path of emb files\n",
    "        if not os.path.exists(emb_output): os.makedirs(emb_output)\n",
    "\n",
    "    def init(self):\n",
    "        super().init() # create or load the graph data using team2vec's init\n",
    "\n",
    "    # it is separated because these params are needed to set up after the model declaration\n",
    "    def init_model(self):\n",
    "        if self.device == 'cpu':\n",
    "            self.loader = self.model.loader(batch_size=self.settings[\"b\"], shuffle=True, num_workers=6)\n",
    "        else:\n",
    "            self.loader = self.model.loader(batch_size=self.settings[\"b\"],shuffle=True)  # cuda doesnt work on the loader if num_workers param is passed\n",
    "        self.optimizer = torch.optim.SparseAdam(list(self.model.parameters()), lr=0.01)\n",
    "\n",
    "    def train(self, num_epochs, log_steps=100, eval_steps=2000):\n",
    "        for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "            self.model.train()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            total_loss = 0\n",
    "            for i, (pos_rw, neg_rw) in enumerate(self.loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.model.loss(pos_rw.to(self.device), neg_rw.to(self.device))\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                if (i + 1) % log_steps == 0:\n",
    "                    print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(self.loader)}, '\n",
    "                           f'Loss: {total_loss / log_steps:.4f}'))\n",
    "                    total_loss = 0\n",
    "\n",
    "                # if (i + 1) % eval_steps == 0:\n",
    "                #     acc = self.test() # the method needs to be modified\n",
    "                #     print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
    "                #            f'Acc: {acc:.4f}'))\n",
    "\n",
    "            # acc = m2v.test()\n",
    "            # print(f'Epoch: {epoch}, Accuracy: {acc:.4f}')\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, train_ratio=0.1):\n",
    "        self.model.eval()\n",
    "\n",
    "        z = self.model('member', batch=self.data['member'].y_index.to(self.device))\n",
    "        y = self.data['member'].y\n",
    "\n",
    "        perm = torch.randperm(z.size(0))\n",
    "        train_perm = perm[:int(z.size(0) * train_ratio)]\n",
    "        test_perm = perm[int(z.size(0) * train_ratio):]\n",
    "\n",
    "        return self.model.test(z[train_perm], y[train_perm], z[test_perm], y[test_perm],\n",
    "                          max_iter=150)\n",
    "\n",
    "\n",
    "# -teamsvecs= ./../../../data/preprocessed/dblp/dblp.v12.json.filtered.mt75.ts3/\n",
    "# --output=./../../../data/preprocessed/dblp/dblp.v12.json.filtered.mt75.ts3/\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # load the graph files, or create them from the parent classes\n",
    "    teamsvecs = './../../../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl'\n",
    "    indexes = './../../../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl'\n",
    "    output = './../../../data/preprocessed/dblp/toy.dblp.v12.json/gnn/stm.undir.mean.'\n",
    "    emb_output = './../../../data/preprocessed/dblp/toy.dblp.v12.json/emb/'\n",
    "\n",
    "    m2v = M2V(teamsvecs, indexes, settings, output, emb_output)\n",
    "    m2v.init()\n",
    "\n",
    "    # only one metapath definition is possible\n",
    "    # sample metapath from https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/metapath2vec.py\n",
    "    # metapath = [\n",
    "    #     ('author', 'writes', 'paper'),\n",
    "    #     ('paper', 'published_in', 'venue'),\n",
    "    #     ('venue', 'publishes', 'paper'),\n",
    "    #     ('paper', 'written_by', 'author'),\n",
    "    # ]\n",
    "\n",
    "    m2v.model = MetaPath2Vec(m2v.data.edge_index_dict, embedding_dim=m2v.settings['d'],\n",
    "                         metapath=m2v.settings['metapath'], walk_length=m2v.settings['walk_length'], context_size=m2v.settings['context_size'],\n",
    "                         walks_per_node=m2v.settings['walks_per_node'], num_negative_samples=m2v.settings['ns'],\n",
    "                         sparse=True).to(m2v.device)\n",
    "\n",
    "    m2v.init()\n",
    "    m2v.train(m2v.settings['e'])\n",
    "    m2v.model.eval()\n",
    "    emb = {}\n",
    "    node_types = m2v.data._node_store_dict.keys()\n",
    "    for node_type in node_types:\n",
    "        emb[node_type] = m2v.model(node_type)  # output of skill embedding\n",
    "    embedding_output = f'{m2v.emb_output}.emb.pt'\n",
    "    torch.save(emb, embedding_output, pickle_protocol=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg_explore",
   "language": "python",
   "name": "pyg_explore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
